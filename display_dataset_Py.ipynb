{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des differentes données sous forme de time series:\n",
    "\n",
    "***\n",
    "\n",
    "- les précipitations de pluies sur 24h\n",
    "- les précipitations horaire\n",
    "- la profondeur d'eau souterraine <br><br>\n",
    " _A partir des données receuillis sur les 10 dernières années par les capteurs pluviométrique et piézométrique_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation de Librairie\n",
    "***\n",
    "- Panda: pour les dataframe\n",
    "- Numpy: pour les manipulation de nombre et calcul\n",
    "- os: pour retrouver les données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "#from utils import Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 15)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#np.set_printoptions(precision=5, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilisateur\\Workspace_lab\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les chemins des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_GW = r\"csv_prepro\\GW\"\n",
    "path_RG_24 = r\"csv_prepro\\RG\\precipiation_RG\"\n",
    "path_RG_1 = r\"csv_prepro\\RG\\precipitation_1h_RG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_geo_RG = r\"geo\\geo_RG.txt\"\n",
    "path_geo_GW = r\"geo\\geo_GW.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodes\n",
    "***\n",
    "- prepocess_2(src): return src(dataframe) prend un dataframe pour caster la colonne de Date vers le type Date(pandas).\n",
    "- prepocess_3(src): return src(dataframe) pareil mais prend en compte l'heure.\n",
    "- generate_dataset(source): return dataset(dataframe) récupère tous les fichiers du dossier source afin d'extraire au forma Dataframe les données et les pré-traiter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "date_parser = pd.to_datetime\n",
    "\n",
    "def get_dataset(source):\n",
    "    f = FloatProgress(min=0, max=100, description=\"Data preprocessing: \", bar_style=\"info\")\n",
    "    display(f)\n",
    "    all_files = [f for f in listdir(cwd +\"\\\\\"+ source) if isfile(join(cwd +\"\\\\\"+ source, f))]\n",
    "    dataset = {}\n",
    "    dtypes = {'Date': 'str', 'Valeur': 'float'}\n",
    "    parse_dates = ['Date']\n",
    "    for txt in all_files:\n",
    "        data_tmp = pd.read_csv(cwd +\"\\\\\"+ source + r\"\\\\\" + str(txt), sep=\";\", dtype=dtypes, parse_dates=parse_dates)\n",
    "        dataset[str(txt)] = data_tmp\n",
    "        f.value += 100/len(all_files)\n",
    "    print(\"Load \" + str(source) + \": Done\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_data(source):\n",
    "    data = pd.read_csv(cwd +\"\\\\\"+ source, sep=\";\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data_GW = get_geo_data(path_geo_GW)\n",
    "geo_data_RG = get_geo_data(path_geo_RG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_rng_dict(dict_data):\n",
    "    k, v = next(iter(dict_data.items()))\n",
    "    print(\"Capteur: \" + k)\n",
    "    print(v.info())\n",
    "    print(v.head())\n",
    "    print(v.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les dataset, variable représentant les données\n",
    "***\n",
    "- GW grand water, données piézométriques\n",
    "- RG rain gauge, donnée pluviométrique (24: journalier, 1: horaire)\n",
    "\n",
    "__ Attention le preprocessing des données est long __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90504dcf6f9147e0b6d4f97b848496b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Data preprocessing: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load csv_prepro\\RG\\precipiation_RG: Done\n"
     ]
    }
   ],
   "source": [
    "data_RG_24 = get_dataset(path_RG_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e01f6c1fb64a579a7152257dd5d9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Data preprocessing: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load csv_prepro\\RG\\precipitation_1h_RG: Done\n"
     ]
    }
   ],
   "source": [
    "data_RG_1 = get_dataset(path_RG_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796d1791b63f4227b3f52a8bfd17133e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Data preprocessing: ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load csv_prepro\\GW: Done\n"
     ]
    }
   ],
   "source": [
    "data_GW = get_dataset(path_GW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capteur: 24h_RG002.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4092 entries, 0 to 4091\n",
      "Data columns (total 2 columns):\n",
      "Date      4092 non-null datetime64[ns]\n",
      "Valeur    4092 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 64.0 KB\n",
      "None\n",
      "        Date  Valeur\n",
      "0 2002-12-22     0.8\n",
      "1 2002-12-23     0.0\n",
      "2 2002-12-24     0.0\n",
      "3 2002-12-25     0.0\n",
      "4 2002-12-26     0.4\n",
      "           Date  Valeur\n",
      "4087 2014-03-01     0.0\n",
      "4088 2014-03-02     0.0\n",
      "4089 2014-03-03     1.4\n",
      "4090 2014-03-04     0.0\n",
      "4091 2014-03-05     0.0\n",
      "########################################################\n",
      "\n",
      "Capteur: RG005.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102268 entries, 0 to 102267\n",
      "Data columns (total 2 columns):\n",
      "Date      102268 non-null datetime64[ns]\n",
      "Valeur    102268 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 1.6 MB\n",
      "None\n",
      "                 Date  Valeur\n",
      "0 2002-12-18 01:00:00     0.0\n",
      "1 2002-12-18 02:00:00     0.0\n",
      "2 2002-12-18 03:00:00     0.0\n",
      "3 2002-12-18 04:00:00     0.0\n",
      "4 2002-12-18 05:00:00     0.0\n",
      "                      Date  Valeur\n",
      "102263 2014-08-18 00:00:00     0.0\n",
      "102264 2014-08-18 01:00:00     0.0\n",
      "102265 2014-08-18 02:00:00     0.0\n",
      "102266 2014-08-18 03:00:00     0.0\n",
      "102267 2014-08-18 04:00:00     0.0\n",
      "########################################################\n",
      "\n",
      "Capteur: GW_011.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17628 entries, 0 to 17627\n",
      "Data columns (total 2 columns):\n",
      "Date      17628 non-null datetime64[ns]\n",
      "Valeur    17628 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 275.5 KB\n",
      "None\n",
      "                 Date  Valeur\n",
      "0 2012-10-30 15:04:42  552.90\n",
      "1 2012-10-30 16:04:42  552.89\n",
      "2 2012-10-30 18:04:42  552.88\n",
      "3 2012-10-30 19:04:42  552.87\n",
      "4 2012-10-30 20:04:42  552.86\n",
      "                     Date  Valeur\n",
      "17623 2014-11-06 06:00:00  552.53\n",
      "17624 2014-11-06 07:00:00  552.52\n",
      "17625 2014-11-06 08:00:00  552.51\n",
      "17626 2014-11-06 09:00:00  552.51\n",
      "17627 2014-11-06 10:00:00  552.51\n"
     ]
    }
   ],
   "source": [
    "info_rng_dict(data_RG_24)\n",
    "print(\"########################################################\")\n",
    "print(\"\")\n",
    "info_rng_dict(data_RG_1)\n",
    "print(\"########################################################\")\n",
    "print(\"\")\n",
    "info_rng_dict(data_GW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouvelles lib\n",
    "***\n",
    "- plotly\n",
    "- cufflinks\n",
    "- seaborn\n",
    "- matplotlib\n",
    "\n",
    "multiples librairies d'affichage graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from plotly.graph_objs import Scatter, Figure, Layout\n",
    "#from plotly.graph_objs import *\n",
    "#import cufflinks as cf\n",
    "#import random\n",
    "#from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.cluster\n",
    "#from scipy.spatial.distance import euclidean\n",
    "#from fastdtw import fastdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2c74b68b92c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#ax = plt.scatter(projection='3d')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'3d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Data for a three-dimensional line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mzlineG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeo_data_GW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alt\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "#ax = plt.scatter(projection='3d')\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Data for a three-dimensional line\n",
    "zlineG = geo_data_GW[\"alt\"]\n",
    "xlineG = geo_data_GW[\"lon\"]\n",
    "ylineG = geo_data_GW[\"lat\"]\n",
    "#ax.plot3D(xlineG, ylineG, zlineG, 'red')\n",
    "ax.scatter(xlineG, ylineG, zlineG, c='red')\n",
    "\n",
    "zlineR = geo_data_RG[\"alt\"]\n",
    "xlineR = geo_data_RG[\"lon\"]\n",
    "ylineR = geo_data_RG[\"lat\"]\n",
    "#ax.plot3D(xlineR, ylineR, zlineR, 'blue')\n",
    "ax.scatter(xlineR, ylineR, zlineR, c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data_GW_c = geo_data_GW.copy()\n",
    "geo_data_RG_c = geo_data_RG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data_GW_c[\"alt\"] = geo_data_GW_c[\"alt\"].apply(lambda x: x//50 + 10)\n",
    "geo_data_RG_c[\"alt\"] = geo_data_RG_c[\"alt\"].apply(lambda x: x//50 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trace_GW = go.Scattergl(\n",
    "x = geo_data_GW_c[\"lon\"],\n",
    "y = geo_data_GW_c[\"lat\"],\n",
    "mode = \"markers\",\n",
    "name = \"GW\",\n",
    "marker = dict(size = geo_data_GW_c[\"alt\"]),\n",
    "text= geo_data_GW_c[\"capteur\"]\n",
    ")\n",
    "\n",
    "trace_RG = go.Scattergl(\n",
    "x = geo_data_RG_c[\"lon\"],\n",
    "y = geo_data_RG_c[\"lat\"],\n",
    "mode = \"markers\",\n",
    "name = \"RG\",\n",
    "marker = dict(size = geo_data_RG_c[\"alt\"]),\n",
    "text= geo_data_RG_c[\"capteur\"]\n",
    ")\n",
    "\n",
    "fig = dict(data=[trace_GW, trace_RG], layout = {\n",
    "        'xaxis': {'title': 'Lon'},\n",
    "        'yaxis': {'title': \"Lat\"}\n",
    "        })\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methode d'affichage\n",
    "*Note: L'affichage d'aussi larges Dataset peu affecter les perfomances de votre navigateur* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(data, mode):\n",
    "    all_trace = []\n",
    "    for key, value in data.items():\n",
    "        trace = go.Scattergl(\n",
    "        x = value[\"Date\"],\n",
    "        y = value[\"Valeur\"],\n",
    "        mode = str(mode),\n",
    "        name = str(key) \n",
    "        )\n",
    "        all_trace.append(trace)\n",
    "\n",
    "    fig = dict(data=all_trace,layout = {\n",
    "            'xaxis': {'title': 'Le temps'},\n",
    "            'yaxis': {'title': \"La valeur\"}\n",
    "            })\n",
    "    iplot(fig)\n",
    "    #iplot(fig, image='png') # Sauvegarde une image en png du plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data, nb = 3):\n",
    "    rolling = data.rolling(window=nb)\n",
    "    rolling_mean = rolling.mean()\n",
    "    print(rolling_mean)\n",
    "    return rolling_mean[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "def normalize(data):\n",
    "    #print(data.head())\n",
    "    # prepare data for standardization\n",
    "    values = data[\"Valeur\"]\n",
    "    values = values.values.reshape((len(values), 1))\n",
    "    # train the standardization\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(values)\n",
    "    #print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
    "    # standardization the dataset and print the first 5 rows\n",
    "    data[\"Valeur\"] = scaler.transform(values)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_normalized(data, mode):\n",
    "    all_trace = []\n",
    "    for key, value in data.items():\n",
    "        value = normalize(value)\n",
    "        trace = go.Scattergl(\n",
    "        x = value[\"Date\"],\n",
    "        y = value[\"Valeur\"],\n",
    "        mode = str(mode),\n",
    "        name = str(key) \n",
    "        )\n",
    "        all_trace.append(trace)\n",
    "    fig = dict(data=all_trace,layout = {\n",
    "            'xaxis': {'title': 'Le temps'},\n",
    "            'yaxis': {'title': \"La valeur\"}\n",
    "            })\n",
    "    iplot(fig)\n",
    "    #iplot(fig, image='png') # Sauvegarde une image en png du plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def plot_scatter_light(data):\n",
    "    rcParams['figure.figsize'] = 15, 6\n",
    "    colors = matplotlib.colors.cnames.copy()\n",
    "    for key, value in data.items():\n",
    "        df = value.set_index(\"Date\")\n",
    "        df = pd.to_numeric(df.Valeur)\n",
    "        trc = plt.plot(df, color=colors.popitem()[0],label = key)\n",
    "    plt.legend(loc=2)\n",
    "    plt.title('Light TS plot')\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_year(data, year):\n",
    "    res = {}\n",
    "    for k, v in data.items():\n",
    "        v = v.set_index(\"Date\")\n",
    "        try:\n",
    "            v = v[year]\n",
    "            v = v.reset_index()\n",
    "            res[k] = v\n",
    "        except KeyError:\n",
    "            print(k + \": pas de données en \" + year)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_year_month(data, year, month):\n",
    "    res = {}\n",
    "    for k, v in data.items():\n",
    "        v = v.set_index(\"Date\")\n",
    "        try:\n",
    "            v = v[year +\"-\"+ month]\n",
    "            v = v.reset_index()\n",
    "            res[k] = v\n",
    "        except KeyError:\n",
    "            print(k + \": pas de données en \" + year +\"-\"+ month)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_year_multi_month(data, year, months):\n",
    "    res = {}\n",
    "    for k, v in data.items():\n",
    "        v = v.set_index(\"Date\")\n",
    "        tmp = pd.DataFrame({'A' : []})\n",
    "        try:\n",
    "            for m in months:\n",
    "                if tmp.empty:\n",
    "                    tmp = v[year +\"-\"+ m]\n",
    "                else:\n",
    "                    #tmp.append(v[year +\"-\"+ m], ignore_index=True)\n",
    "                    #tmp = tmp.merge(v[year +\"-\"+ m], left_index=True, right_index=True, how='inner')\n",
    "                    tmp = pd.concat([tmp, v[year +\"-\"+ m]])\n",
    "            #v = v[year +\"-\"+ month]\n",
    "            tmp = tmp.reset_index()\n",
    "            #print(tmp)\n",
    "            #print(tmp)\n",
    "            res[k] = tmp\n",
    "        except KeyError:\n",
    "            print(k + \": pas de données en \" + year +\"-\"+ str(m))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2015\"\n",
    "#month = \"06\"\n",
    "months = [\"08\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace: RG_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = data_RG_24.copy()\n",
    "data_2012 = split_data_year(data, year)\n",
    "data_2012_01 = split_year_multi_month(data_2012, year, months)\n",
    "\n",
    "#plot_scatter_light(data)\n",
    "plot_scatter(data, \"markers+lines\")\n",
    "#plot_scatter(data_2012_01_02, \"markers+lines\")\n",
    "#plot_scatter_normalized(data_2012_01, \"markers+lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace: RG_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_RG_1.copy()\n",
    "data_2012 = split_data_year(data, year)\n",
    "data_2012_01_02 = split_year_multi_month(data_2012, year, months)\n",
    "#data_2012_01 = split_year_month(data_2012, year, month)\n",
    "\n",
    "#plot_scatter_light(data)\n",
    "#plot_scatter(data_2012_01_02, \"markers+lines\")\n",
    "plot_scatter_normalized(data_2012_01_02, \"markers+lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace: GW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = data_GW.copy()\n",
    "data_2012 = split_data_year(data, year)\n",
    "data_2012_01_02 = split_year_multi_month(data_2012, year, months)\n",
    "#data_2012_01 = split_year_month(data_2012, year, month)\n",
    "\n",
    "#plot_scatter_light(data)\n",
    "#plot_scatter(data_2012_01_02, \"markers+lines\")\n",
    "plot_scatter_normalized(data_2012_01_02, \"markers+lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from utils import func"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "func.python_feather(data_GW, \"feather\\\\GW\\\\\")\n",
    "func.python_feather(data_RG_1, \"feather\\\\RG_1\\\\\")\n",
    "func.python_feather(data_RG_24, \"feather\\\\RG_24\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n",
    "from tslearn.utils import to_time_series\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_equal(iterator):\n",
    "    iterator = iter(iterator)\n",
    "    try:\n",
    "        first = next(iterator)\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return all(first == rest for rest in iterator)\n",
    "\n",
    "def tslearn_format_export(dict_set):\n",
    "    df = []\n",
    "    for k, v in dict_set.items():\n",
    "        if not check_equal(v[\"Valeur\"].values):\n",
    "            df.append(v[\"Valeur\"].values)  \n",
    "    df_set = to_time_series_dataset(df)\n",
    "    df_set = TimeSeriesResampler(743).fit_transform(df_set)\n",
    "    return df_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_year_month_multi_day(data, year, month, days):\n",
    "    res = {}\n",
    "    for k, v in data.items():\n",
    "        v = v.set_index(\"Date\")\n",
    "        tmp = pd.DataFrame({'A' : []})\n",
    "        try:\n",
    "            for d in days:\n",
    "                if tmp.empty:\n",
    "                    tmp = v[year +\"-\"+ month + \"-\" + d]\n",
    "                else:\n",
    "                    #tmp.append(v[year +\"-\"+ m], ignore_index=True)\n",
    "                    #tmp = tmp.merge(v[year +\"-\"+ m], left_index=True, right_index=True, how='inner')\n",
    "                    tmp = pd.concat([tmp, v[year +\"-\"+ month + \"-\" + d]])\n",
    "            #v = v[year +\"-\"+ month]\n",
    "            tmp = tmp.reset_index()\n",
    "            #print(tmp)\n",
    "            #print(tmp)\n",
    "            res[k] = tmp\n",
    "        except KeyError:\n",
    "            print(k + \": pas de données en \" + year +\"-\"+ month + \"-\" + d)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012_01_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_set_1 = split_year_month_multi_day(data_2012_01_02, \"2015\", \"8\", [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\"])\n",
    "dict_set_2 = split_year_month_multi_day(data_2012_01_02, \"2015\", \"8\", [\"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\"])\n",
    "sample_1 = tslearn_format_export(dict_set_1)\n",
    "sample_2 = tslearn_format_export(dict_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "sample.extend(sample_1)\n",
    "sample.extend(sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(len(sample)))\n",
    "for elmt in sample:\n",
    "    print(\"is Nan: \" + str(np.isnan(np.sum(elmt))) + \", Len: \" + str(len(elmt)) + \", first value: \" + str(elmt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = TimeSeriesResampler(48).fit_transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdtw_km = TimeSeriesKMeans(n_clusters=3, metric=\"softdtw\", metric_params={\"gamma_sdtw\": .01},\n",
    "                           verbose=True, random_state=seed)\n",
    "sample_clust = sdtw_km.fit_predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(sample_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "colors = [\"-r\", \"-b\", \"-g\"]\n",
    "for yi in range(3):\n",
    "    plt.subplot(3, 3, 4 + yi)\n",
    "    #print(yi)\n",
    "    for xx in sample[sample_clust == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(sdtw_km.cluster_centers_[yi].ravel(), colors[yi])\n",
    "    plt.xlim(0, 48)\n",
    "    plt.ylim(-4, 4)\n",
    "    if yi == 1:\n",
    "        plt.title(\"Soft-DTW $k$-means\")\n",
    "plt.tight_layout()\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
